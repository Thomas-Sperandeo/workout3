bty = 'n',
cex = 1
)
grid()
#' @title descriptive
#' @description function which provides numeric statistics on a numeric vector
#' @param x x is a vector (numeric)
#' @param na.rm na.rm is a condition which determines whether to remove missing values before evaluating (logical)
#' @return computes minimum, 1st quartile, median, mean, 3rd quartile, maximum, range, interquartile range and standard deviation of x
descriptive <- function(x = 0, na.rm = FALSE) {
min <- min(x, na.rm = na.rm)
q1 <- quantile(x, probs = 0.25, na.rm = na.rm)
median <- median(x, na.rm = na.rm)
mean <- mean(x, na.rm = na.rm)
q3 <- quantile(x, probs = 0.75, na.rm = na.rm)
max <- max(x, na.rm = na.rm)
range <- max - min
iqr <- q3 - q1
sd <- sd(x, na.rm = na.rm)
summary <- c(min, q1, median, mean, q3, max, range, iqr, sd)
label_names <-
c(
'Minimum',
'1st Quartile',
'Median',
'Mean',
'3rd Quartile',
'Maximum',
'Range',
'Interquartile Range',
'Standard Deviation'
)
names(summary) <- label_names
return(summary)
}
# input vectors
set.seed(100)
x <- rnorm(100)
y <- x
y[sample(1:10, size = 10)] <- NA
y
# test set 2
descriptive(x)
descriptive(y)
descriptive(y, na.rm = TRUE)
descriptive(letters)
# test set 2
a <- descriptive(x)
class(a)
length(a)
names(a)
descriptive(y, na.rm = TRUE)
descriptive(letters)
a <- descriptive(x)
class(a)
length(a)
names(a)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", cex = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1
)
grid()
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", cex = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
legend(
'topright',
c(
expression(paste(italic(mu == 0, ", ", sigma ^ 2 == 0.2))),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1
)
grid()
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", cex = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1
)
grid()
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", cex = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "FFFFFF"
)
grid()
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", cex = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "FFFFFF"
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 8)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "FFFFFF"
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 20)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "FFFFFF"
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 20)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "#6EB812"
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 20)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "white"
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 20)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "white",
text.font = 3
)
plot(x_values, gaussian(x_values, 0, sqrt(0.2)), las = 1, type = "l", lwd = 2, ylim = c(0,1), col = "#0B146E", ylab = expression(paste(varphi[mu * sigma^2], (chi))), xlab = expression(chi), main = "Figure 1: Normal Probability Density Functions", pch = 20)
lines(x_values, gaussian(x_values, 0, 1), col = "#f32012")
lines(x_values, gaussian(x_values, 0, sqrt(5)), col = "#F6E20E")
lines(x_values, gaussian(x_values, -2, sqrt(0.5)), col = "#6EB812")
grid()
legend(
'topright',
c(
italic(expression(paste(mu == 0, ", ", sigma ^ 2 == 0.2))),
expression(paste(mu == 0, ", ", sigma ^ 2 == 1)),
expression(paste(mu == 0, ", ", sigma ^ 2 == 5)),
expression(paste(mu == -2, ", ", sigma ^ 2 == 0.5))
),
lty = 1,
col = c('#0B146E', '#f32012', '#F6E20E', '#6EB812'),
bty = 'n',
cex = 1,
bg = "white"
)
knitr::opts_chunk$set(echo = TRUE)
csv <- "https://raw.githubusercontent.com/ucb-stat133/stat133-labs/master/data/text-emotion.csv"
twitter_data <- read.csv(csv)
head(twitter_data, 10)
library(stringr)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
csv <- "https://raw.githubusercontent.com/ucb-stat133/stat133-labs/master/data/text-emotion.csv"
twitter_data <- read.csv('csv')
knitr::opts_chunk$set(echo = TRUE)
twitter_data <- read.csv("https://raw.githubusercontent.com/ucb-stat133/stat133-labs/master/data/text-emotion.csv")
head(twitter_data, 10)
library(stringr)
library(ggplot2)
View(twitter_data)
str_count(twitter_data, "^ ")
tweet_length <- str_length(twitter_data$content)
tweet_length
summary(tweet_length)
hist <- ggplot(twitter_data) + geom_histogram(aes(tweet_length), binwidth = 5, center = 3)
hist
str_count(twitter_data, "^ ")
str_count(twitter_data$content, "^ ")
str_detect(twitter_data$content, "^ ")
str_extract(twitter_data$content, "^ ")
sum(str_count(twitter_data$content, "^ "))
str_count(twitter_data$content, "^.$")
str_count(twitter_data$content, "^$")
sum(str_count(twitter_data$content, "^$"))
sum(str_count(twitter_data$content, "^.$"))
str_extract(twitter_data$content, "^.$")
str_extract(twitter_data$content, "^.$", na.rm = TRUE)
str_match(twitter_data$content, "^.$")
str_extract(twitter_data$content, "^.$")
str_count(twitter_data$content, "^.$")
sum(str_count(twitter_data$content, "^.$"))
?str_extract
str_count(twitter_data$author, "...............")
str_locate(twitter_data$content, "^.$")
str_count(twitter_data$author, "[A-Z, a-z, 0-9, \\_]+")
sum(str_count(twitter_data$author, "[A-Z, a-z, 0-9, \\_]+"))
str_count(twitter_data$author, "[A-Z, a-z, 0-9, \\_]+")
sum(str_count(twitter_data$author, "[A-Z, a-z, 0-9, \\_]+"))
str_count(twitter_data$content, "\\^")
str_count(twitter_data$content, "\\^")
sum(str_count(twitter_data$content, "\\^"))
sum(tr_count(twitter_data$content, "\\$\\$\\$"))
str_count(twitter_data$author, "\w+")
str_count(twitter_data$author, "\\w+")
sum(str_count(twitter_data$author, "\\w+"))
str_count(twitter_data$content, "\\$\\$\\$\\$\\$\\$")
str_count(twitter_data$content, "\\$\\$\\$\\$\\$\\$")
sum(tr_count(twitter_data$content, "\\$\\$\\$\\$\\$\\$"))
sum(str_count(twitter_data$content, "\\$\\$\\$\\$\\$\\$"))
sum(str_count(twitter_data$content, "\\$\\$\\$"))
sum(str_count(twitter_data$content, "[^a, ^A]"))
sum(str_count(twitter_data$content, "[^a, ^A]+"))
sum(str_count(twitter_data$content, "^[^a, ^A]+$"))
?str_view
str_view(twitter_data$content, "^.$", match = TRUE)
install.packages("htmlwidgets")
knitr::opts_chunk$set(echo = TRUE)
twitter_data <- read.csv("https://raw.githubusercontent.com/ucb-stat133/stat133-labs/master/data/text-emotion.csv")
head(twitter_data, 10)
library(stringr)
library(ggplot2)
library(htmlwidgets)
str_view(twitter_data$content, "^.$", match = TRUE)
str_count(twitter_data$content, "\\!")
summary(str_count(twitter_data$content, "\\!"))
str_count(twitter_data$content, "^\\s$")
sum(str_count(twitter_data$content, "^\\s$"))
summary(tweet_length)
max(str_count(twitter_data$content, "\\!"))
str_locate(twitter_data$content, max(str_count(twitter_data$content, "\\!")))
factor(twitter_data$sentiment)
levels(factor(twitter_data$sentiment))
summary(factor(twitter_data$sentiment))
summary(factor(twitter_data$sentiment)) / 40000
summary(factor(twitter_data$sentiment)) / 40000
barplot <- barplot(summary(factor(twitter_data$sentiment)) / 40000, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = names,las=1)
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = names,las=1)
#Create a vector comprised of different setiment categories
levels(factor(twitter_data$sentiment))
#Compute the frequencies of each sentiment
summary(factor(twitter_data$sentiment))
#Graph relative frequencies
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = names, las=1)
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1)
barplot
?barplot
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1)
barplot
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, ylim = c(0, 0.25))
barplot
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, xlim = c(0, 0.25))
barplot
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, xlim = c(0, 0.22))
barplot
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, xlim = c(0, 0.25))
barplot
levels(factor(twitter_data$sentiment))
str_count(twitter_data$sentiment == levels(factor(twitter_data$sentiment)))
str_length(twitter_data$sentiment, "anger"))
str_length(twitter_data$sentiment, "anger")
str_length(twitter_data$sentiment, "[a][n][g][e][r]")
mean(length(twitter_data$sentiment == "anger"))
mean(nchar(twitter_data$sentiment == "anger"))
nchar(twitter_data$sentiment == "anger")
max(nchar(twitter_data$content))
max(str_count(twitter_data$content, "^.$"))
max(str_count(twitter_data$content, ""))
??display
str_extract(twitter_data$content, "^.$")
remove.na(str_extract(twitter_data$content, "^.$"))
?remove
sum(str_count(twitter_data$content, "^[^a, ^A]+$"))
?head\
?head
head(str_extract(twitter_data$content, "^[^a, ^A]+$"), 10, na.rm = TRUE)
head(str_extract(twitter_data$content, "^[^a, ^A]+$"), 10, na.rm = FALSE)
str_extract(twitter_data$content, "^.$")
sum(str_count(twitter_data$content, "^.$"))
str_count(twitter_data) == 1
str_count(twitter_data$content) == 1
sum(str_count(twitter_data$content) == 1)
which(str_count(twitter_data$content) == 1)
twitter$content[which(str_count(twitter_data$content) == 1)]
twitter_data$content[which(str_count(twitter_data$content) == 1)]
str_count(twitter_data$author, "\\w+") > 15
sum(str_count(twitter_data$author, "\\w+") > 15)
str_count(twitter_data$content) == 1
sum(str_count(twitter_data$content) == 1)
which(str_count(twitter_data$content) == 1)
twitter_data$content[which(str_count(twitter_data$content) == 1)]
str_count(twitter_data$content) == max(length(twitter_data$content))
sum(str_count(twitter_data$content) == max(length(twitter_data$content)))
str_count(twitter_data$content, "") == 184
twitter_data$content[which(str_count(twitter_data$content, "") == 184)]
which(str_count(twitter_data$content, "") == 184)
twitter_data$content[20858]
max(str_count(twitter_data$content, ""))
which(str_count(twitter_data$content, "") == 184)
max(str_count(twitter_data$content, "\\!"))
max(str_count(twitter_data$content, "\\!"))
which(str_count(twitter_data$content, "\\!") == 76)
twitter_data$content[which(str_count(twitter_data$content, "\\!") == 76)]
head(str_extract(twitter_data$content, "^[^a, ^A]+$") == TRUE, 10)
head(str_detect(twitter_data$content, "^[^a, ^A]+$") == TRUE, 10)
sum(str_count(twitter_data$content, "^[^a, ^A]+$"))
which(str_detect(twitter_data$content, "^[^a, ^A]+$") == TRUE)
head(which(str_detect(twitter_data$content, "^[^a, ^A]+$") == TRUE), 10)
twitter_data$content[first_10_cases]
first_10_cases <- head(which(str_detect(twitter_data$content, "^[^a, ^A]+$") == TRUE), 10)
twitter_data$content[first_10_cases]
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, xlim = c(0, 0.25))
barplot
sum(str_count(twitter_data$content, "^[^aA]+$"))
first_10_cases <- head(which(str_detect(twitter_data$content, "^[^a, ^A]+$") == TRUE), 10)
twitter_data$content[first_10_cases]
knitr::opts_chunk$set(echo = TRUE)
twitter_data <- read.csv("https://raw.githubusercontent.com/ucb-stat133/stat133-labs/master/data/text-emotion.csv")
head(twitter_data, 10)
library(stringr)
library(ggplot2)
library(htmlwidgets)
library(dplyr)
levels(factor(twitter_data$sentiment))
twitter_data$length <- str_count(twitter_data$content)
twitter_data$length <- str_count(twitter_data$content)
twitter_data %>% group_by(sentiment) %>% summarize(mean(length))
#Tweets with one character
str_count(twitter_data$content) == 1
sum(str_count(twitter_data$content) == 1)
which(str_count(twitter_data$content) == 1)
which(str_count(twitter_data$content, "") == 184)
max(str_count(twitter_data$content, ""))
twitter_data$content[which(str_count(twitter_data$content, "") == 184)]
which(str_count(twitter_data$content, "") == 184)
max(str_count(twitter_data$content, "."))
twitter_data$content[which(str_count(twitter_data$content, ".") == 184)]
which(str_count(twitter_data$content, ".") == 184)
which.max(nchar(twitter_data$content))
#Tweet with most characters
which.max(nchar(as.character(twitter_data$content)))
#Tweet with most characters
which.max(nchar(as.character(twitter_data$content)))
#creating vectors for tweet length
tweet_length <- str_length(twitter_data$content)
tweet_length
summary(tweet_length)
#Histogram of twet length
hist <- ggplot(twitter_data) + geom_histogram(aes(tweet_length), binwidth = 5, center = 3)
hist
#Tweets with zero characters
str_count(twitter_data$content, "^\\s$")
sum(str_count(twitter_data$content, "^\\s$"))
#Tweets with one character
str_count(twitter_data$content) == 1
sum(str_count(twitter_data$content) == 1)
which(str_count(twitter_data$content) == 1)
twitter_data$content[which(str_count(twitter_data$content) == 1)]
#Tweet with most characters
which.max(nchar(as.character(twitter_data$content)))
twitter_data$content[which(str_count(twitter_data$content, ".") == 184)]
which(str_count(twitter_data$content, ".") == 184)
which.max(nchar(as.character(twitter_data$content)))
twitter_data$content[which.max(nchar(as.character(twitter_data$content)))]
relative_freq <- summary(factor(twitter_data$sentiment)) / 40000
relative_freq <- sort(relative_freq, decreasing = TRUE)
barplot <- barplot(relative_freq, main = "Relative Frequencies of Sentiments", horiz = TRUE, names.arg = levels(factor(twitter_data$sentiment)), las=1, xlim = c(0, 0.25))
rm(list=ls())
devtools::document()
devtools::check_man()
devtools::test()
devtools::build()
devtools::install()
setwd("C:/Users/tommy/OneDrive/Desktop/Stat_133/workout3/binomial")
devtools::document()
devtools::check_man()
devtools::test()
devtools::build()
devtools::install()
devtools::document()
devtools::check_man()
devtools::test()
devtools::build()
library(binomial)
bin_mean(10, 0.2)
devtools::install()
devtools::build()
library(binomial)
bin_mean()
